# RunPod A40 Benchmark KomutlarÄ±

## ğŸš€ BaÅŸlangÄ±Ã§ Kurulumu (Ä°lk Kez)

```bash
# 1. Ã‡alÄ±ÅŸma dizinine git
cd /workspace

# 2. Repoyu klonla
git clone https://github.com/sariekr/multimodal-embedding
cd multimodal-embedding

# 3. Sistem kÃ¼tÃ¼phanelerini yÃ¼kle
apt-get update && apt-get install -y libgl1-mesa-glx git

# 4. Python kÃ¼tÃ¼phanelerini yÃ¼kle
pip install transformers datasets pillow timm einops protobuf sentencepiece pandas tabulate
pip install colpali-engine flash_attn
```

## ğŸ” Dataset Split KontrolÃ¼ (Ã–NCELÄ°K!)

**âš ï¸ CRITICAL:** V19'da yanlÄ±ÅŸ dataset split kullanÄ±yoruz! Ã–nce doÄŸru split'i bul:

```bash
cd /workspace/multimodal-embedding
git pull origin main
python test_flickr_splits.py
```

**Beklenen Ã§Ä±ktÄ±:**
```
âœ… MATCHES KARPATHY SPLIT!
   Train: 29,000 (expected ~29k)
   Val:   1,014 (expected ~1k)
   Test:  1,000 (expected ~1k)
```

**EÄŸer match etmezse:**
- âŒ nlphuji/flickr30k doÄŸru split'e sahip deÄŸil
- âŒ lmms-lab/flickr30k zaten 31K sample'lÄ±k (yanlÄ±ÅŸ)
- ğŸ”§ Manual Karpathy split download etmemiz lazÄ±m

## ğŸ”„ GÃ¼ncel Ã‡alÄ±ÅŸtÄ±rma (Repo Var)

### âš ï¸ V19 FIXED (DATASET SPLIT HATASI VAR!)

**ğŸ”´ KULLANMA - YanlÄ±ÅŸ dataset split:**
```bash
cd /workspace/multimodal-embedding
git pull origin main
python run_benchmark_grand_slam_v19_fixed.py  # Critical fixes applied
```

**ğŸ”´ V19 Issues:**
1. âœ… Fixed multi-caption logic (was BROKEN in v18)
2. âŒ WRONG DATASET SPLIT (random 1K from 31K train set)
3. âœ… Proper ground truth mapping
4. âŒ Results NOT comparable to published work

### Legacy Versions (Deprecated)
```bash
# V18 - Has critical bugs, don't use
python run_benchmark_grand_slam_v18.py  # âŒ BROKEN multi-caption logic
```

## âš ï¸ v17 Ã‡ALIÅTIRMA (HatalÄ± - Kullanma!)

v17'de bug var: `N=31783` (train set) yÃ¼klÃ¼yor, test set (5K) yerine.

## âœ… v18 Ã‡alÄ±ÅŸtÄ±rma (DÃ¼zeltilmiÅŸ)

```bash
python run_benchmark_grand_slam_v18.py
```

**Beklenen Ã§Ä±ktÄ±:**
```
âœ“ Loaded Flickr30k test set: 1000 samples  # <-- 1K daha hÄ±zlÄ±
âœ“ Loaded Winoground: 400 samples
```

**SÃ¼re tahmini:**
- 8 models Ã— 1K Flickr Ã— bidirectional = ~2-3 saat
- Maliyet: ~$6-9 (A40 @ $3/hr)

## ğŸ” SonuÃ§ DosyalarÄ±

```bash
# SonuÃ§larÄ± kontrol et
cat benchmark_v18_results.csv

# SonuÃ§larÄ± local'e indir (yeni terminalde)
scp root@RUNPOD_IP:/workspace/multimodal-embedding/benchmark_v18_results.csv .
```

## ğŸ›‘ Pod'u Durdurmak

RunPod web interface'den "Stop" butonuna bas veya:
```bash
# Ã‡alÄ±ÅŸmayÄ± iptal et
Ctrl+C

# Pod'u durdur (RunPod web UI'dan)
```

## ğŸ“Š Benchmark VersiyonlarÄ±

| Version | Flickr Samples | Multi-Caption | Direction | Runtime | Status |
|---------|---------------|---------------|-----------|---------|--------|
| v16 | 1,000 (sampled) | âŒ Single only | T2I only | ~3h | âœ… Old |
| v17 | 31,783 (BUG!) | âŒ Single only | T2I + I2T | 15-20h | âŒ Train set bug |
| v18 | 1,000 (sampled) | ğŸ”´ BROKEN | T2I + I2T | ~2-3h | âŒ Critical bugs |
| v19 FIXED | Full test set | âœ… Correct | T2I + I2T | ~3-4h | â­ RECOMMENDED |

**ğŸ”´ V18 Critical Bugs:**
- Gallery duplicates images for each caption (fatal)
- Diagonal ground truth assumption (wrong)
- Random sampling breaks comparisons

## ğŸ¯ Multi-Seed Benchmark (Ã–NERÄ°LEN) â­

### Neden Multi-Seed?
Peer review feedback'e gÃ¶re:
- âœ… Statistical significance iÃ§in 5 run gerekli
- âœ… Mean Â± std ile confidence intervals
- âœ… "87.5% vs 87.8%" gibi farklarÄ±n anlamlÄ± olup olmadÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼rsÃ¼n

### Ã‡alÄ±ÅŸtÄ±rma
```bash
cd /workspace/multimodal-embedding
git pull origin main
bash run_multi_seed_benchmark.sh
```

**Beklenen Ã‡Ä±ktÄ±:**
```
Running 5 iterations with seeds: [42, 123, 456, 789, 1011]

### RUN 1/5 - SEED=42
...
### RUN 5/5 - SEED=1011
...

âœ… Aggregated results saved to: benchmark_v18_multiseed_aggregated.csv
```

### SonuÃ§ FormatÄ±
```
Model         | Flickr T2I_R@1  | Flickr I2T_R@1
Apple-DFN5B-H | 89.8Â±0.3%       | 89.1Â±0.4%
LAION-CLIP-H  | 87.5Â±0.2%       | 87.8Â±0.3%
```

**Ã–zellikler:**
- âœ… 5 seeds: Statistical rigor
- âœ… Mean Â± std: Confidence intervals
- âœ… 12-15 saat runtime
- âœ… ~$45 maliyet (A40 @ $3/hr)
- âœ… Peer-review ready

## ğŸ“ Notlar

- **Quick test** iÃ§in: `python run_benchmark_grand_slam_v18.py` (tek seed)
- **Production/paper** iÃ§in: `bash run_multi_seed_benchmark.sh` (5 seeds)
- **v17'yi kullanma** - train set bug'Ä± var
